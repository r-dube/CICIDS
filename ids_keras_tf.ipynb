{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ids_keras_tf.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9zmYLdZDxJHVcnVID/H1W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/CICIDS/blob/main/ids_keras_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the top modules that are used in multiple places\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Some global variables to drive the script\n",
        "# data_url is the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# Data is loaded from a prepocessed dataset\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/CICIDS/main/MachineLearningCVE/processed/bal-cicids2017.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYEbuZO0MHyf"
      },
      "source": [
        "# label names (YY) in the data and their\n",
        "# mapping to numerical values\n",
        "label_map = {\n",
        " 'BENIGN' : 0,\n",
        " 'FTP-Patator' : 1,\n",
        " 'SSH-Patator' : 2,\n",
        " 'DoS slowloris' : 3,\n",
        " 'DoS Slowhttptest': 4,\n",
        " 'DoS Hulk' : 5,\n",
        " 'DoS GoldenEye' : 6,\n",
        " 'Heartbleed' : 7,\n",
        " 'Web Attack � Brute Force' : 8,\n",
        " 'Web Attack � XSS' : 8,\n",
        " 'Web Attack � Sql Injection' : 8,\n",
        " 'Infiltration' : 9,\n",
        " 'Bot' : 10,\n",
        " 'PortScan' : 11,\n",
        " 'DDoS' : 12,\n",
        "}\n",
        "\n",
        "num_ids_features = 76\n",
        "num_ids_classes = 13\n",
        "ids_classes = [ 'BENIGN', 'FTP-Patator', 'SSH-Patator', 'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye', 'Heartbleed', 'Brute Force', 'XSS', 'Sql Injection', 'Infiltration', 'Bot', 'PortScan', 'DDoS',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "# Utility functions used by classifiers\n",
        "# In particular to load and split data and output results\n",
        "def ids_load_df_from_csv():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print (\"load Dataframe shape\", df.shape)\n",
        "\n",
        "    return df\n",
        "\n",
        "def ids_split(df):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Dataframe that has columns of covariates followed by a column of labels\n",
        "    Returns:\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test as numpy arrays\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    numcols = len(df.columns)\n",
        "    print(\"df.shape\", df.shape)\n",
        "\n",
        "    X = df.iloc[:, 0:numcols-1]\n",
        "    y = df.loc[:, 'YY']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "    print (\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "    print (\"X_val.shape\", X_val.shape, \"y_val.shape\", y_val.shape)\n",
        "    print (\"X_test.shape\", X_test.shape, \"y_test.shape\", y_test.shape)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    y_train = y_train.values\n",
        "    y_val = y_val.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "def ids_accuracy (y_actual, y_pred):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Numpy arrays with actual and predicted labels\n",
        "    Returns:\n",
        "        multiclass accuracy and f1 scores; two class accuracy and f1 scores\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    # modify labels to get results for two class classification\n",
        "    y_actual_2 = (y_actual > 0).astype(int)\n",
        "    y_pred_2 = (y_pred > 0).astype(int)\n",
        "\n",
        "    acc = accuracy_score (y_actual, y_pred)\n",
        "    f1 = f1_score(y_actual, y_pred, average='macro')\n",
        "    acc_2 = accuracy_score (y_actual_2, y_pred_2)\n",
        "    f1_2 = f1_score(y_actual_2, y_pred_2)\n",
        "    \n",
        "    return acc, f1, acc_2, f1_2\n",
        "    \n",
        "\n",
        "def ids_metrics(y_actual, y_pred):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Numpy arrays with actual and predicted labels\n",
        "    Returns:\n",
        "        None\n",
        "    Print: various classification metrics\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix (y_actual, y_pred)\n",
        "    print (cm)\n",
        "\n",
        "    acc, f1, acc_2, f1_2 = ids_accuracy (y_actual, y_pred)\n",
        "    print('Classifier accuracy : {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "    print('Two class classifier accuracy : {:.4f}'.format(acc_2), 'F1 score: {:.4f}'.format(f1_2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw5VdTF_1phq"
      },
      "source": [
        "# Original model based on Colab tutorials\n",
        "# Load Keras and Tensorflow modules\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__\n",
        "\n",
        "df = ids_load_df_from_csv ()\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = ids_split(df)\n",
        "\n",
        "inputs = keras.Input(shape=(num_ids_features,), name=\"ids_fcnn\")\n",
        "x1 = layers.Dense(num_ids_features, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "x2 = layers.Dense(num_ids_features, activation=\"relu\", name=\"dense_2\")(x1)\n",
        "outputs = layers.Dense(num_ids_classes, name=\"output\")(x2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_ids_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_ids_classes)\n",
        "print (\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "print (\"X_val.shape\", X_val.shape, \"y_val.shape\", y_val.shape)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=8,\n",
        "    epochs=10,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSD3PeyoH3b"
      },
      "source": [
        "# New FFNN model developed using the deeplizard tutorial\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "\n",
        "df = ids_load_df_from_csv ()\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = ids_split(df)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(units=num_ids_features, input_shape=(num_ids_features, ), activation='relu'),\n",
        "    Dense(units=num_ids_features, activation='relu'),\n",
        "    Dense(units=num_ids_classes, activation='linear')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001), \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x=X_train, \n",
        "    y=y_train, \n",
        "    batch_size=10, \n",
        "    epochs=2, \n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lefP_sNootg5"
      },
      "source": [
        "()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}