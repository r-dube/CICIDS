{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ids_keras_tf.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNctWZ2L/yVZy9tEokgnbuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/CICIDS/blob/main/ids_keras_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the top modules that are used in multiple places\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Some global variables to drive the script\n",
        "# data_url is the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# Data is loaded from a prepocessed dataset\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/CICIDS/main/MachineLearningCVE/processed/bal-cicids2017.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYEbuZO0MHyf"
      },
      "source": [
        "# label names (YY) in the data and their\n",
        "# mapping to numerical values\n",
        "label_map = {\n",
        " 'BENIGN' : 0,\n",
        " 'FTP-Patator' : 1,\n",
        " 'SSH-Patator' : 2,\n",
        " 'DoS slowloris' : 3,\n",
        " 'DoS Slowhttptest': 4,\n",
        " 'DoS Hulk' : 5,\n",
        " 'DoS GoldenEye' : 6,\n",
        " 'Heartbleed' : 7,\n",
        " 'Web Attack � Brute Force' : 8,\n",
        " 'Web Attack � XSS' : 8,\n",
        " 'Web Attack � Sql Injection' : 8,\n",
        " 'Infiltration' : 9,\n",
        " 'Bot' : 10,\n",
        " 'PortScan' : 11,\n",
        " 'DDoS' : 12,\n",
        "}\n",
        "\n",
        "num_ids_features = 76\n",
        "num_ids_classes = 13\n",
        "ids_classes = [ 'BENIGN', 'FTP-Patator', 'SSH-Patator', 'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye', 'Heartbleed', 'Brute Force', 'XSS', 'Sql Injection', 'Infiltration', 'Bot', 'PortScan', 'DDoS',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "# Utility functions used by classifiers\n",
        "# In particular to load and split data and output results\n",
        "def ids_load_df_from_csv():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print (\"load Dataframe shape\", df.shape)\n",
        "\n",
        "    return df\n",
        "\n",
        "def ids_split(df):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Dataframe that has columns of covariates followed by a column of labels\n",
        "    Returns:\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test as numpy arrays\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    numcols = len(df.columns)\n",
        "    print(\"df.shape\", df.shape)\n",
        "\n",
        "    X = df.iloc[:, 0:numcols-1]\n",
        "    y = df.loc[:, 'YY']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "    print (\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "    print (\"X_val.shape\", X_val.shape, \"y_val.shape\", y_val.shape)\n",
        "    print (\"X_test.shape\", X_test.shape, \"y_test.shape\", y_test.shape)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    y_train = y_train.values\n",
        "    y_val = y_val.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "def ids_accuracy (y_actual, y_pred):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Numpy arrays with actual and predicted labels\n",
        "    Returns:\n",
        "        multiclass accuracy and f1 scores; two class accuracy and f1 scores\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    # modify labels to get results for two class classification\n",
        "    y_actual_2 = (y_actual > 0).astype(int)\n",
        "    y_pred_2 = (y_pred > 0).astype(int)\n",
        "\n",
        "    acc = accuracy_score (y_actual, y_pred)\n",
        "    f1 = f1_score(y_actual, y_pred, average='macro')\n",
        "    acc_2 = accuracy_score (y_actual_2, y_pred_2)\n",
        "    f1_2 = f1_score(y_actual_2, y_pred_2)\n",
        "    \n",
        "    return acc, f1, acc_2, f1_2\n",
        "    \n",
        "\n",
        "def ids_metrics(y_actual, y_pred):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        Numpy arrays with actual and predicted labels\n",
        "    Returns:\n",
        "        None\n",
        "    Print: various classification metrics\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix (y_actual, y_pred)\n",
        "    print (cm)\n",
        "\n",
        "    acc, f1, acc_2, f1_2 = ids_accuracy (y_actual, y_pred)\n",
        "    print('Classifier accuracy : {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "    print('Two class classifier accuracy : {:.4f}'.format(acc_2), 'F1 score: {:.4f}'.format(f1_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSD3PeyoH3b"
      },
      "source": [
        "# FCNN model developed using the deeplizard tutorial\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "# For reproducible results\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "df = ids_load_df_from_csv ()\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = ids_split(df)\n",
        "\n",
        "# To use sparse_categorical_crossentropy as the loss function\n",
        "#   use softmax as the activation function in the output layer\n",
        "inputs = keras.Input(shape=(num_ids_features,), name=\"ids_input\")\n",
        "hl1 = Dense(num_ids_features, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "hl2 = Dense(num_ids_features, activation=\"relu\", name=\"dense_2\")(hl1)\n",
        "outputs = Dense(num_ids_classes, activation=\"softmax\", name=\"output\")(hl2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "initial_learning_rate = 0.004\n",
        "epochs = 30\n",
        "decay = initial_learning_rate / epochs\n",
        "\n",
        "# learning scheduler 1\n",
        "def lr_time_based_decay(epoch, lr):\n",
        "    return lr * 1 / (1 + decay * epoch)\n",
        "\n",
        "# learning scheuler 2\n",
        "def lr_step_decay(epoch, lr):\n",
        "    drop_rate = 0.75\n",
        "    epochs_drop = 2\n",
        "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tb_cbk = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=initial_learning_rate), \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x=X_train, \n",
        "    y=y_train, \n",
        "    batch_size=64, \n",
        "    shuffle=True,\n",
        "    epochs=epochs, \n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[LearningRateScheduler(lr_time_based_decay, verbose=1), tb_cbk],\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itR5eQDXIyLk"
      },
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances\n",
        "\n",
        "# Control TensorBoard display. If no port is provided, \n",
        "# the most recently launched TensorBoard is used\n",
        "# notebook.display(port=6006, height=1000) \n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYH7gu-tNshX"
      },
      "source": [
        "# prediction step and metrics similar to logistic and knn classifiers\n",
        "predictions = model.predict(\n",
        "    x=X_val,\n",
        "    batch_size=64,\n",
        "    verbose=0,\n",
        ") \n",
        "\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "ids_metrics(y_val, y_pred) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}