---
title: Retrying principal component analysis and gaussian mixture models
---
We create a simpler dataset and use principal component analysis (PCA) and gaussian mixture models (GMMs) over this dataset.

### The simpler dataset
First, we modify our data processing script ([^scripts1]) to create a small dataset ([^data3]) with just two classes. The first class is the BENIGN class (label 0) and the second is the PortScan class (label 11). Both classes have 8,000 samples for a total of 16,000 rows in the dataset.

The main idea here is to reduce the complexity of visualizing multiple classes in the same chart. We hope that the simplification will result in an improved understanding of the features (or alternatively principal components) in the data.
 
### Dimensionality reduction with PCA
Next, we reduce the dimensionality of the data using PCA and plot the actual labels (as colors) against the pincipal components (two components at a time). From the plots, we see that the BENIGN class (normal trafic on the network) has a lot more variability compared to the PortScan class (where an attacker uses a software tool to probe servers for open ports). Intuitively, the variability observation makes sense as the the natural traffic on a network encompasses many different application and user types. Attackers typically seek to hide their traffic within this natural variability.

Principal components one, two
![Principal components one, two](/CICIDS/assets/images/2020-11-17-twoclass-1.png)

Principal components three, four
![Principal components three, four](/CICIDS/assets/images/2020-11-17-twoclass-2.png)

Principal components five, six
![Principal components five, six](/CICIDS/assets/images/2020-11-17-twoclass-3.png)

### Sanity check with logistic regression
We do a quick sanity check with logist regression. Logistic regression is able to separate out the two classes with 99%+ accuracy (on a test set, separate from the training set; there is no validation set in this experiment).

### GMMs do not fit
Finally, we fit a GMM against an unlabeled version of the dataset. We find that GMM badly underfits, assigning 2,452 samples to one class and 13,548 to the other. A great fit would find ~8,000 samples for both classes. We conclude, at least in the case of the two-class dataset, that GMMs are not a good method to discover the structure of the data.

### References
[^scripts1]: [Data processing script for local machine](https://github.com/r-dube/CICIDS/blob/main/scripts/ids_utils.py)
[^data3]: [Two-class attack data](https://github.com/r-dube/CICIDS/blob/main/MachineLearningCVE/processed/twoclass-cicids2017.csv)
[^colab6]: [Experimentation wth two classes on Colab](https://github.com/r-dube/CICIDS/blob/main/ids_twoclass.ipynb)
